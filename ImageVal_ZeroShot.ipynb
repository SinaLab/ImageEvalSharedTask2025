{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c4a1950995c541318241be6f2d199a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9dc656c7cd8b400fb0cb7210a33781c4",
              "IPY_MODEL_f56a32095f20453baf2f59b42ec5be45",
              "IPY_MODEL_7b07434d0fcf481bbfdbd20edbbcaba8"
            ],
            "layout": "IPY_MODEL_441d47433d0149c38c3c4694d0d006fd"
          }
        },
        "9dc656c7cd8b400fb0cb7210a33781c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0cfcd702980403ea84e0d7a36fafb35",
            "placeholder": "​",
            "style": "IPY_MODEL_894dfacf3d594b12922946efea25ef14",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f56a32095f20453baf2f59b42ec5be45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f11b0966a1a9462b9a9960c4eebfcafe",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0040c7ac3bac490099c3fbc8841aa663",
            "value": 5
          }
        },
        "7b07434d0fcf481bbfdbd20edbbcaba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2665f4fa1f2e4ef88c65080e00b1dd06",
            "placeholder": "​",
            "style": "IPY_MODEL_7d4b6e6428624ec38a25f16a4bd6eff6",
            "value": " 5/5 [00:05&lt;00:00,  2.13s/it]"
          }
        },
        "441d47433d0149c38c3c4694d0d006fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0cfcd702980403ea84e0d7a36fafb35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "894dfacf3d594b12922946efea25ef14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f11b0966a1a9462b9a9960c4eebfcafe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0040c7ac3bac490099c3fbc8841aa663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2665f4fa1f2e4ef88c65080e00b1dd06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4b6e6428624ec38a25f16a4bd6eff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SinaLab/ImageEvalSharedTask2025/blob/main/ImageVal_ZeroShot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qwen_vl_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3h6sB70mzOy",
        "outputId": "5e1a4221-8441-4bfc-e258-acd0d2c60de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qwen_vl_utils\n",
            "  Downloading qwen_vl_utils-0.0.11-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting av (from qwen_vl_utils)\n",
            "  Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from qwen_vl_utils) (24.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from qwen_vl_utils) (11.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from qwen_vl_utils) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->qwen_vl_utils) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->qwen_vl_utils) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->qwen_vl_utils) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->qwen_vl_utils) (2025.6.15)\n",
            "Downloading qwen_vl_utils-0.0.11-py3-none-any.whl (7.6 kB)\n",
            "Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av, qwen_vl_utils\n",
            "Successfully installed av-14.4.0 qwen_vl_utils-0.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
        "from qwen_vl_utils import process_vision_info\n",
        "from PIL import Image\n",
        "import torch\n",
        "import os\n",
        "import csv"
      ],
      "metadata": {
        "id": "cxwEK6ljmvAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weT8-5QeE7sG",
        "outputId": "26f9c43f-f35a-4523-87a1-7930ada6ebc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c4a1950995c541318241be6f2d199a78",
            "9dc656c7cd8b400fb0cb7210a33781c4",
            "f56a32095f20453baf2f59b42ec5be45",
            "7b07434d0fcf481bbfdbd20edbbcaba8",
            "441d47433d0149c38c3c4694d0d006fd",
            "f0cfcd702980403ea84e0d7a36fafb35",
            "894dfacf3d594b12922946efea25ef14",
            "f11b0966a1a9462b9a9960c4eebfcafe",
            "0040c7ac3bac490099c3fbc8841aa663",
            "2665f4fa1f2e4ef88c65080e00b1dd06",
            "7d4b6e6428624ec38a25f16a4bd6eff6"
          ]
        },
        "id": "Wlj8Rx8_mKX1",
        "outputId": "b833536b-f11d-4ed1-c0ad-16fed32b3707"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4a1950995c541318241be6f2d199a78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to process ISH.PH03.05B.092.jpg: CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacity of 14.74 GiB of which 482.12 MiB is free. Process 22656 has 14.27 GiB memory in use. Of the allocated memory 13.33 GiB is allocated by PyTorch, and 834.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.057.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 496.12 MiB is free. Process 22656 has 14.25 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 1004.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05C.002.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 496.12 MiB is free. Process 22656 has 14.25 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 1012.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.070.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 496.12 MiB is free. Process 22656 has 14.25 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 1012.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.054.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.075.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.095.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.097.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.040.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.038.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.076.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.068.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1004.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.061.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.065.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.021.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05C.003.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.069.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.044.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.080.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.045.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.059.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.066.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.082.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.032.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.029.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.033.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.105.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.074.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.096.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.046.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.100.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.077.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.084.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05C.006.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05C.007.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05C.001.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.030.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.026.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.060.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.058.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.103.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.071.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.050.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.072.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.036.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 974.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05C.005.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.022.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.056.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.073.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.099.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.087.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.037.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.011.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.107.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.024.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.031.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.043.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.067.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.098.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.106.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.048.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05C.004.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.051.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, and 1013.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.039.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.090.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05C.008.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.047.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.034.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.104.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.018.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.035.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.053.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.052.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.028.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.063.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.085.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.064.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.055.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.041.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.062.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.049.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.081.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, and 1014.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.108.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.091.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.038.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 971.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.056.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.055.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.009.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.013.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.033.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 995.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.060.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.020.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, and 1013.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.073.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.039.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.054.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.037.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.077.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1009.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.071.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.010.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, and 1013.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.004.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.066.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.075.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.059.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.028.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.015.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.025.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.026.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.051.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.019.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.007.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.058.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.044.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.017.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.003.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.072.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.002.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.005.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.007.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.079.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 981.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.008.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 978.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.014.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 978.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.062.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.023.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.027.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.076.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.053.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.046.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.023.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.063.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.057.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.012.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.067.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.068.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 964.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.070.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 963.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.042.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 967.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.078.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 967.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.001.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.006.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.061.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.016.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.035.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.074.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.031.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.032.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.065.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.064.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.069.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 974.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.080.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, and 1016.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.081.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 997.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05B.042.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.030.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.019.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.008.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.015.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.025.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.029.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 997.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.057.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.044.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.003.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.042.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.040.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.032.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.033.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.012.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.008.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.023.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.027.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.012.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.041.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.006.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.005.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.039.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.021.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.038.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.029.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.040.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.036.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.014.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 981.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.045.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.043.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.045.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.017.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.047.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 966.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.037.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.004.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.011.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.026.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.009.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.016.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.017.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.007.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.018.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.037.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.025.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 981.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.010.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.006.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.010.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 997.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.034.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.048.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.053.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.016.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.015.2.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 981.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.009.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.038.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.061.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 973.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.051.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.043.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.058.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 966.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.050.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.015.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, and 1016.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.027.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.031.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.013.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.024.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.052.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, and 1017.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.028.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.024.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.002.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.020.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.014.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.039.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.005.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.056.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.035.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.036.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.002.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.052.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.013.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 981.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.062.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 969.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.003.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.05.001.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 997.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.049.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.004.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.011.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.04.019.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.065.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.087.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.102.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.091.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.005.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 978.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.018.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.021.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.092.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.112.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.011.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.106.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.058.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.078.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 978.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.030.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 965.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.063.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 979.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.099.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 979.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.084.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.010.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.103.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.017.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.022.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.098.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.104.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 997.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.004.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 979.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.015.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 973.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.029.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.007.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 981.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.041.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.080.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.060.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 972.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.001.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 965.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.048.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.054.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 979.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.111.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 997.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.040.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 979.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.081.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.072.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.026.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.003.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 972.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.057.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.006.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 978.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.105.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.097.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.095.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.071.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.064.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.085.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.036.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.066.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.025.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 977.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.089.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.090.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.009.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.027.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.002.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.088.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.113.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, and 1016.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.028.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.033.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.093.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.016.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.031.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.068.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 979.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.115.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.020.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.061.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.035.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.060.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 971.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.055.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.008.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.019.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 983.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.108.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 978.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.094.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.051.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.034.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.040.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 995.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.083.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.047.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.021.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.049.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.016.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.073.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.048.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.056.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.026.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 995.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.036.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.043.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.03.034.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.032.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 969.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.024.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.045.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.010.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.014.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.062.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.074.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.028.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.025.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.017.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.082.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.039.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.052.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.001.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.037.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.041.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.044.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1010.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.079.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 976.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.035.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.045.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.027.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.002.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1009.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.031.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 973.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.053.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 974.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.039.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 973.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.067.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.008.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.037.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.029.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 1000.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.023.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.042.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.075.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.019.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.040.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.018.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.042.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.020.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.033.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1004.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.059.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.038.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.069.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.022.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.005.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.043.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.046.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.009.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.003.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 998.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.041.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.047.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.025.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.032.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.035.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.036.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.044.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.127.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 978.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.128.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.024.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.004.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.001.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.015.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.121.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.013.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 999.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.010.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.008.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 997.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.129.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.016.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.015.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.006.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.031.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.028.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.130.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.013.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.029.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.123.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.019.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.026.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.038.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.012.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.018.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.027.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.006.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.034.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.007.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.017.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.125.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.124.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.023.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.021.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.022.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.046.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.020.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.033.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.126.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH03.02.011.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 996.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.122.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.100.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.118.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.113.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.115.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 995.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.103.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.062.01.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 973.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.098.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 972.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.114.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 975.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.030.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.080.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.078.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 995.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.085.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 995.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.044.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.082.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.104.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.112.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.107.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.119.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.102.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.073.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.106.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.011.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.066.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.108.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 997.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.086.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.096.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.014.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.090.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.067.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.071.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.064.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.105.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.059.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 979.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.054.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.110.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.065.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.075.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.076.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.009.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.060.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.099.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.109.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.077.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.005.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 995.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.074.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1011.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.101.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.111.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.097.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.063.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.084.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.120.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.116.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.003.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.068.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.094.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.117.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.007.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24B.002.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.095.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.009.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.050.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.045.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.122.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.072.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.016.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.007.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.057.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.015.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.088.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.021.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.035.01.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.132.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.049.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.081.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.061.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.023.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1009.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.019.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.020.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.079.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.002.03.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.047.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.027.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.008.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.083.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1011.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.018.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.014.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.025.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.022.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.127.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.010.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1010.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.058.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.129.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.130.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.056.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.123.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.036.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.093.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.032.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.107.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.087.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.011.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.131.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.034.02.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.048.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.030.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.070.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.026.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.013.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.089.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.002.02.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.012.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.126.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.017.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.046.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.004.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.001.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.124.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.038.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.034.01.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.039.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.128.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.028.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.040.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.003.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.037.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.052.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.035.02.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 995.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.069.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.051.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.117.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.024.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.053.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.100.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.101.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.080.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.121.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.072.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.068.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.120.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.116.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.079.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.067.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.112.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.104.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.061.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.094.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.063.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.064.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.115.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.083.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.113.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.085.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.073.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 981.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.088.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.095.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.110.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 995.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.081.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.091.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.099.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.119.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.125.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.109.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.059.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.086.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.092.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.096.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.075.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.084.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.060.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 982.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.106.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.082.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.108.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.087.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1010.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.097.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.098.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 993.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.089.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.105.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.118.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.077.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1009.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.111.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.069.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.093.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.114.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 979.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.103.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.102.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.090.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.24.055.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.108.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.100.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.088.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.054.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.118.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.052.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.095.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.058.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.053.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.045.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.048.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.046.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.110.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.099.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.111.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1009.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.112.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.038.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.107.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.039.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.044.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.085.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.034.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.042.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.115.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.040.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.101.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.071.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 979.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.102.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.050.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.032.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.117.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.127.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.116.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.120.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.076.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.167.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.041.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.056.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.043.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 992.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.066.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 994.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.036.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1010.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.047.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 988.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.057.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 991.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.078.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 995.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.049.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.055.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 990.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.084.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.065.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.037.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.051.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 989.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.103.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 987.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.081.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.070.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 980.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.074.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 978.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.083.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 979.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.13.035.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 986.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.075.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.063.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.092.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.068.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.045.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.055.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.059.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.082.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.043.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.086.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.053.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.057.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.047.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.060.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.048.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.097.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.106.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.061.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.037.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.040.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.071.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1008.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.074.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.035.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1009.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.065.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.056.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.051.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.046.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.067.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.076.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.079.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.064.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.078.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.105.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.087.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.069.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.062.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.090.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.093.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.077.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.066.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.044.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.089.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.080.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.072.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.104.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.073.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.070.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.058.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.091.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.004.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.020.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.013.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.019.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.041.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.014.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.024.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.042.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1009.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.021.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.016.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.034.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.050.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1009.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.054.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.025.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.032.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.049.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.026.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.036.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 984.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.030.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.031.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.12 GiB is allocated by PyTorch, and 1009.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.027.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.039.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.006.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.052.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.005.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.003.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.010.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.028.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.007.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.011.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.022.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.015.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.008.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.009.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.033.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.001.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.002.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.023.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.012.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.038.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.017.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Failed to process ISH.PH01.12.018.jpg: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.74 GiB of which 524.12 MiB is free. Process 22656 has 14.23 GiB memory in use. Of the allocated memory 13.14 GiB is allocated by PyTorch, and 985.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        }
      ],
      "source": [
        "# Load processor and model\n",
        "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "    \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"eager\"\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
        "\n",
        "# Define folder path for images\n",
        "image_folder = \"/content/drive/MyDrive/ImageVal/Test/images\"\n",
        "output_csv = \"/content/drive/MyDrive/ImageVal/Test/Test_dataset_captions_nofinetune_2nd_round.csv\"\n",
        "\n",
        "# Prepare CSV file for writing\n",
        "with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"image_file\", \"arabic_caption\"])\n",
        "\n",
        "    # Process each image in the folder\n",
        "    for image_file in os.listdir(image_folder):\n",
        "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_path = os.path.join(image_folder, image_file)\n",
        "            try:\n",
        "                image = Image.open(image_path)\n",
        "                messages = [\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\"type\": \"image\", \"image\": image},\n",
        "                            {\n",
        "                                \"type\": \"text\",\n",
        "                                \"text\": (\n",
        "                                     \"You are an expert in visual scene understanding and multilingual caption generation.\"\n",
        "                                     \"Analyze the content of this image, which is potentially related to the palestnian Nakba\"\n",
        "                                     \"and Israeli occupation of Palestine, and provide a concise and meaningful caption in Arabic - about 15 to 50 words.\"\n",
        "                                     \"The caption should reflect the scene's content, emotional context, and should be natural and culturally appropriate.\"\n",
        "                                     \" Do not include any English or metadata — The caption must be in Arabic.\"\n",
        "                                ),\n",
        "                            },\n",
        "                        ],\n",
        "                    }\n",
        "                ]\n",
        "\n",
        "                text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "                image_inputs, _ = process_vision_info(messages)\n",
        "                inputs = processor(\n",
        "                    text=[text],\n",
        "                    images=image_inputs,\n",
        "                    padding=True,\n",
        "                    return_tensors=\"pt\",\n",
        "                )\n",
        "                inputs = inputs.to(model.device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
        "\n",
        "                generated_ids_trimmed = [\n",
        "                    out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "                ]\n",
        "                output_text = processor.batch_decode(\n",
        "                    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "                )\n",
        "\n",
        "                print(f\"{image_file}: {output_text[0]}\")\n",
        "                writer.writerow([image_file, output_text[0]])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process {image_file}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_-sHdwgA7Ep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}